{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eab1d916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from glob import glob\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4d34c505",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"data_augmentation = tf.keras.Sequential([layers.experimental.preprocessing.RandomZoom((1,1),(1,1), fill_mode='nearest'),\n",
    "                                         layers.experimental.preprocessing.RandomZoom((1,1),(0,0), fill_mode='nearest'),\n",
    "    layers.experimental.preprocessing.RandomHeight((2, 2.5)),\n",
    "    layers.experimental.preprocessing.RandomWidth((1,1.2)),\n",
    "    layers.experimental.preprocessing.RandomRotation(0.08, fill_mode='nearest'),\n",
    "    layers.experimental.preprocessing.RandomTranslation((-0.1,0.1), (-0.1,0.1), fill_mode='nearest'),\n",
    "    layers.experimental.preprocessing.Resizing(random.randrange(299,900), random.randrange(299,900), interpolation='bilinear')\n",
    "])\"\"\"\n",
    "\n",
    "\n",
    "data_augmentation_type1 = tf.keras.Sequential([#layers.experimental.preprocessing.RandomZoom((1,1),(0.4,0.4), fill_mode='nearest'),\n",
    "                                               layers.experimental.preprocessing.RandomZoom((1,1),(0.0,0.0), fill_mode='nearest'),\n",
    "                                         layers.experimental.preprocessing.RandomZoom((1,1),(0,0), fill_mode='nearest'),\n",
    "    layers.experimental.preprocessing.RandomZoom((0,0.5),(0,0.5), fill_mode='nearest'),\n",
    "    layers.experimental.preprocessing.RandomRotation(0.05, fill_mode='nearest'),\n",
    "    #layers.experimental.preprocessing.RandomTranslation((-0.045,0.045), (-0.1,0.1), fill_mode='nearest'),\n",
    "    layers.experimental.preprocessing.RandomTranslation((-0.005,0.005), (-0.05,0.05), fill_mode='nearest'),\n",
    "    \n",
    "    #layers.experimental.preprocessing.Resizing(random.randrange(250,299), random.randrange(250,299), interpolation='bilinear'),\n",
    "    layers.experimental.preprocessing.Resizing(300, 300, interpolation='bilinear'),\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "data_augmentation_type2 = tf.keras.Sequential([#layers.experimental.preprocessing.RandomZoom((1,1),(0.4,0.4), fill_mode='nearest'),\n",
    "    layers.experimental.preprocessing.RandomZoom((1,1),(0.0,0.0), fill_mode='nearest'),\n",
    "                                         layers.experimental.preprocessing.RandomZoom((0.5,0.5),(0,0), fill_mode='nearest'),\n",
    "    layers.experimental.preprocessing.RandomZoom((0,0.5),(0,0.5), fill_mode='nearest'),\n",
    "    layers.experimental.preprocessing.RandomRotation(0.05, fill_mode='nearest'),\n",
    "    #layers.experimental.preprocessing.RandomTranslation((-0.045,0.045), (-0.1,0.1), fill_mode='nearest'),\n",
    "    layers.experimental.preprocessing.RandomTranslation((-0.005,0.005), (-0.05,0.05), fill_mode='nearest'),\n",
    "    \n",
    "    #layers.experimental.preprocessing.Resizing(random.randrange(250,299), random.randrange(250,299), interpolation='bilinear'),\n",
    "    layers.experimental.preprocessing.Resizing(300, 300, interpolation='bilinear'),\n",
    "])\n",
    "\n",
    "\n",
    "data_augmentation_type3 = tf.keras.Sequential([#layers.experimental.preprocessing.RandomZoom((1,1),(0.4,0.4), fill_mode='nearest'),\n",
    "    layers.experimental.preprocessing.RandomZoom((1,1),(0.0,0.0), fill_mode='nearest'),\n",
    "                                         layers.experimental.preprocessing.RandomZoom((1,1),(0,0), fill_mode='nearest'),\n",
    "    layers.experimental.preprocessing.RandomZoom((0,0.5),(0,0.5), fill_mode='nearest'),\n",
    "    layers.experimental.preprocessing.RandomRotation(0.04, fill_mode='nearest'),\n",
    "    #layers.experimental.preprocessing.RandomTranslation((-0.045,0.045), (-0.1,0.1), fill_mode='nearest'),\n",
    "                                               layers.experimental.preprocessing.RandomTranslation((-0.005,0.005), (-0.05,0.05), fill_mode='nearest'),\n",
    "    \n",
    "    layers.experimental.preprocessing.Resizing(random.randrange(250,299), random.randrange(250,299), interpolation='bilinear'),\n",
    "    layers.experimental.preprocessing.Resizing(300, 300, interpolation='bilinear'),\n",
    "])\n",
    "\n",
    "\n",
    "data_augmentation_type4 = tf.keras.Sequential([#layers.experimental.preprocessing.RandomZoom((1,1),(0.3,0.3), fill_mode='nearest'),\n",
    "    layers.experimental.preprocessing.RandomZoom((1,1),(0.0,0.0), fill_mode='nearest'),\n",
    "                                            layers.experimental.preprocessing.RandomZoom((1,1),(0,0), fill_mode='nearest'),\n",
    "                                               layers.experimental.preprocessing.RandomZoom((1,1),(0,0), fill_mode='nearest'),\n",
    "    layers.experimental.preprocessing.RandomZoom((0.5,0.5),(0.5,0.5), fill_mode='nearest'),\n",
    "    layers.experimental.preprocessing.RandomRotation(0.04, fill_mode='nearest'),\n",
    "    #layers.experimental.preprocessing.RandomTranslation((-0.045,0.045), (-0.1,0.1), fill_mode='nearest'),\n",
    "                                               layers.experimental.preprocessing.RandomTranslation((-0.005,0.005), (-0.05,0.05), fill_mode='nearest'),\n",
    "    \n",
    "    #layers.experimental.preprocessing.Resizing(random.randrange(250,299), random.randrange(250,299), interpolation='bilinear'),\n",
    "    layers.experimental.preprocessing.Resizing(300, 300, interpolation='bilinear'),\n",
    "])\n",
    "\n",
    "data_augmentation_type5 = tf.keras.Sequential([#layers.experimental.preprocessing.RandomZoom((1,1),(0.4,0.4), fill_mode='nearest'),\n",
    "    layers.experimental.preprocessing.RandomZoom((1,1),(0.0,0.0), fill_mode='nearest'),\n",
    "    layers.experimental.preprocessing.RandomZoom((0,0.5),(0,0.5), fill_mode='nearest'),\n",
    "    layers.experimental.preprocessing.RandomRotation(0.05, fill_mode='nearest'),\n",
    "    #layers.experimental.preprocessing.RandomTranslation((-0.045,0.045), (-0.1,0.1), fill_mode='nearest'),\n",
    "                                               layers.experimental.preprocessing.RandomTranslation((-0.005,0.005), (-0.05,0.05), fill_mode='nearest'),\n",
    "    \n",
    "    #layers.experimental.preprocessing.Resizing(random.randrange(250,299), random.randrange(250,299), interpolation='bilinear'),\n",
    "    layers.experimental.preprocessing.Resizing(300, 300, interpolation='bilinear'),\n",
    "])\n",
    "\n",
    "data_augmentation_type6 = tf.keras.Sequential([#layers.experimental.preprocessing.RandomZoom((1,1),(0.4,0.4), fill_mode='nearest'),\n",
    "    layers.experimental.preprocessing.RandomZoom((1,1),(0.0,0.0), fill_mode='nearest'),\n",
    "                                         layers.experimental.preprocessing.RandomZoom((0.5,0.5),(0,0), fill_mode='nearest'),\n",
    "    layers.experimental.preprocessing.RandomZoom((0,0.5),(0,0.5), fill_mode='nearest'),\n",
    "    layers.experimental.preprocessing.RandomRotation(0.04, fill_mode='nearest'),\n",
    "    #layers.experimental.preprocessing.RandomTranslation((-0.045,0.045), (-0.1,0.1), fill_mode='nearest'),\n",
    "                                               layers.experimental.preprocessing.RandomTranslation((-0.005,0.005), (-0.05,0.05), fill_mode='nearest'),\n",
    "    \n",
    "    #layers.experimental.preprocessing.Resizing(random.randrange(250,299), random.randrange(250,299), interpolation='bilinear'),\n",
    "    layers.experimental.preprocessing.Resizing(300, 300, interpolation='bilinear'),\n",
    "])\n",
    "\n",
    "data_augmentation_type7 = tf.keras.Sequential([layers.experimental.preprocessing.RandomZoom((0,1),(0,1), fill_mode='nearest'),\n",
    "    layers.experimental.preprocessing.RandomRotation(0.01, fill_mode='nearest'),\n",
    "    layers.experimental.preprocessing.RandomTranslation((-0.005,0.005), (-0.05,0.05), fill_mode='nearest'),\n",
    "    #layers.experimental.preprocessing.Resizing(random.randrange(80,299), random.randrange(80,299), interpolation='bilinear'),\n",
    "    layers.experimental.preprocessing.Resizing(300, 300, interpolation='bilinear')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "01958e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_color_from_file(img_path):\n",
    "    img1 = cv2.imread(img_path)\n",
    "\n",
    "    gray = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
    "    _, th = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    cnt,labels = cv2.connectedComponents(th)\n",
    "\n",
    "    for i in range(cnt):\n",
    "        img1[labels==i] = [int(j) for j in np.random.randint(0,255,3)]\n",
    "\n",
    "    cv2.imwrite(img_path, img1)\n",
    "    \n",
    "def change_color_from_loaded_data(img):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    _, th = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    cnt,labels = cv2.connectedComponents(th)\n",
    "\n",
    "    for i in range(cnt):\n",
    "        img[labels==i] = [int(j) for j in np.random.randint(0,255,3)]\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7ec709a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_making_before_augmentation(img_path):\n",
    "    img_raw = cv2.imread(img_path)\n",
    "    #(height, width, channel) = img_raw.shape\n",
    "    #image_maden = np.full((height*5, width*3, channel), 255, dtype=np.uint8)\n",
    "    #image_maden[height*2:height*3, width*1:width*2, :] = img_raw\n",
    "    return img_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1cd279e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29985 29986 29990 29993 29985 29995\n"
     ]
    }
   ],
   "source": [
    "image_files1 = glob('img/train/img_raw/type1/*.jpg')\n",
    "image_files2 = glob('img/train/img_raw/type2/*.jpg')\n",
    "image_files3 = glob('img/train/img_raw/type3/*.jpg')\n",
    "image_files4 = glob('img/train/img_raw/type4/*.jpg')\n",
    "image_files5 = glob('img/train/img_raw/type5/*.jpg')\n",
    "image_files6 = glob('img/train/img_raw/type6/*.jpg')\n",
    "\n",
    "image_files11 = glob('img/train/img/type1/*.jpg')\n",
    "image_files22 = glob('img/train/img/type2/*.jpg')\n",
    "image_files33 = glob('img/train/img/type3/*.jpg')\n",
    "image_files44 = glob('img/train/img/type4/*.jpg')\n",
    "image_files55 = glob('img/train/img/type5/*.jpg')\n",
    "image_files66 = glob('img/train/img/type6/*.jpg')\n",
    "\n",
    "image_files111 = glob('img/train/img_small/type1/*.jpg')\n",
    "image_files222 = glob('img/train/img_small/type2/*.jpg')\n",
    "image_files333 = glob('img/train/img_small/type3/*.jpg')\n",
    "image_files444 = glob('img/train/img_small/type4/*.jpg')\n",
    "image_files555 = glob('img/train/img_small/type5/*.jpg')\n",
    "image_files666 = glob('img/train/img_small/type6/*.jpg')\n",
    "print(len(image_files1),len(image_files2),len(image_files3),len(image_files4),len(image_files5),len(image_files6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "fe4c0ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files_raw_list = [image_files1, image_files2, image_files3, image_files4, image_files5, image_files6]\n",
    "image_files_to_save_list = [image_files11, image_files22, image_files33, image_files44, image_files55, image_files66]\n",
    "image_files_to_small_list = [image_files111, image_files222, image_files333, image_files444, image_files555, image_files666]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8ee38889",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation_type_list = [data_augmentation_type1,data_augmentation_type2,data_augmentation_type3,\n",
    "                               data_augmentation_type4,data_augmentation_type5,data_augmentation_type6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2f60ba62",
   "metadata": {},
   "outputs": [],
   "source": [
    "#while True:\n",
    "for (image_files_raw, image_to_save_raw, data_augmentation) in zip(image_files_raw_list, image_files_to_save_list, data_augmentation_type_list):\n",
    "    for (image_file, image_file_to_save) in (zip(image_files_raw, image_to_save_raw)):\n",
    "        image_to_process = image_making_before_augmentation(image_file)\n",
    "        image_to_process = change_color_from_loaded_data(image_to_process)\n",
    "        image_to_process = tf.expand_dims(image_to_process, 0)\n",
    "        if random.randrange(0,10) == 1:\n",
    "            augmented_image = data_augmentation_type7(image_to_process)\n",
    "        else:\n",
    "            augmented_image = data_augmentation(image_to_process)\n",
    "        augmented_image = augmented_image[0].numpy().astype(\"uint8\")\n",
    "        cv2.imwrite(image_file_to_save, augmented_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266248a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation_type7 = tf.keras.Sequential([layers.experimental.preprocessing.RandomZoom((0,1),(0,1), fill_mode='nearest'),\n",
    "    layers.experimental.preprocessing.RandomRotation(0.01, fill_mode='nearest'),\n",
    "    layers.experimental.preprocessing.RandomTranslation((-0.005,0.005), (-0.05,0.05), fill_mode='nearest'),\n",
    "    layers.experimental.preprocessing.Resizing(299, 299, interpolation='bilinear')\n",
    "])\n",
    "\n",
    "\n",
    "image_files1 = glob('img/train/img/type1/*.jpg')\n",
    "\n",
    "for image_file in tqdm(image_files):\n",
    "    image_to_process = image_making_before_augmentation(image_file)\n",
    "    image_to_process = change_color_from_loaded_data(image_to_process)\n",
    "    image_to_process = tf.expand_dims(image_to_process, 0)\n",
    "\n",
    "    augmented_image = data_augmentation_type7(image_to_process)\n",
    "    augmented_image = augmented_image[0].numpy().astype(\"uint8\")\n",
    "    cv2.imwrite(image_file, augmented_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d7cc0672",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:08,  1.42s/it]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"data_augmentation_type7 = tf.keras.Sequential([layers.experimental.preprocessing.RandomZoom((0,1),(0,1), fill_mode='nearest'),\n",
    "    layers.experimental.preprocessing.RandomRotation(0.01, fill_mode='nearest'),\n",
    "    layers.experimental.preprocessing.RandomTranslation((-0.005,0.005), (-0.05,0.05), fill_mode='nearest'),\n",
    "    layers.experimental.preprocessing.Resizing(random.randrange(80,299), random.randrange(80,299), interpolation='bilinear'),\n",
    "    layers.experimental.preprocessing.Resizing(299, 299, interpolation='bilinear')\n",
    "])\"\"\"\n",
    "\n",
    "data_augmentation_type7 = tf.keras.Sequential([#layers.experimental.preprocessing.RandomZoom((0,1),(0,1), fill_mode='nearest'),\n",
    "    layers.experimental.preprocessing.RandomRotation(0.01, fill_mode='nearest'),\n",
    "    layers.experimental.preprocessing.RandomTranslation((-0.005,0.005), (-0.05,0.05), fill_mode='nearest'),\n",
    "    #layers.experimental.preprocessing.Resizing(random.randrange(80,600), random.randrange(80,700), interpolation='bilinear'),\n",
    "    #layers.experimental.preprocessing.Resizing(299, 299, interpolation='bilinear')\n",
    "])\n",
    "\n",
    "\n",
    "for (image_files_raw, image_to_save_raw) in tqdm(zip(image_files_raw_list, image_files_to_save_list)):\n",
    "    for (image_file, image_file_to_save) in (zip(image_files_raw, image_to_save_raw)):\n",
    "        image_to_process = image_making_before_augmentation(image_file)\n",
    "        image_to_process = change_color_from_loaded_data(image_to_process)\n",
    "        image_to_process = tf.expand_dims(image_to_process, 0)\n",
    "        augmented_image = data_augmentation_type7(image_to_process)\n",
    "        augmented_image = augmented_image[0].numpy().astype(\"uint8\")\n",
    "        cv2.imwrite(image_file_to_save, augmented_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba50798",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40d52ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37afe7e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "7b7806c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_augmentation(img, ang_range=6, shear_range=3, trans_range=3):\n",
    "    \"\"\"# Rotation\n",
    "    ang_rot = np.random.uniform(ang_range) - ang_range / 2\n",
    "    rows, cols, ch = img.shape\n",
    "    Rot_M = cv2.getRotationMatrix2D((cols / 2, rows / 2), ang_rot, 0.9)\n",
    "\n",
    "    # Translation\n",
    "    tr_x = trans_range * np.random.uniform() - trans_range / 2\n",
    "    tr_y = trans_range * np.random.uniform() - trans_range / 2\n",
    "    Trans_M = np.float32([[1, 0, tr_x], [0, 1, tr_y]])\n",
    "\n",
    "    # Shear\n",
    "    pts1 = np.float32([[5, 5], [20, 5], [5, 20]])\n",
    "\n",
    "    pt1 = 5 + shear_range * np.random.uniform() - shear_range / 2\n",
    "    pt2 = 20 + shear_range * np.random.uniform() - shear_range / 2\n",
    "    pts2 = np.float32([[pt1, 5], [pt2, pt1], [5, pt2]])\n",
    "    shear_M = cv2.getAffineTransform(pts1, pts2)\n",
    "\n",
    "    img = cv2.warpAffine(img, Rot_M, (cols, rows))\n",
    "    img = cv2.warpAffine(img, Trans_M, (cols, rows))\n",
    "    img = cv2.warpAffine(img, shear_M, (cols, rows))\n",
    "\n",
    "    # Brightness\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "    img = np.array(img, dtype=np.float64)\n",
    "    random_bright = .4 + np.random.uniform()\n",
    "    img[:, :, 2] = img[:, :, 2] * random_bright\n",
    "    img[:, :, 2][img[:, :, 2] > 255] = 255\n",
    "    img = np.array(img, dtype=np.uint8)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_HSV2RGB)\"\"\"\n",
    "\n",
    "    # Blur\n",
    "    blur_value = random.randint(0,1) + 1\n",
    "    #rows, cols, ch = img.shape\n",
    "    #img = cv2.resize(img, (random.randrange(int((cols-1)*0.5), cols), random.randrange(int((rows-1)*0.5), rows)) )\n",
    "    img = cv2.blur(img,(blur_value, blur_value))\n",
    "\n",
    "    return img\n",
    "\n",
    "def add_noise(noise_type,image):\n",
    "    if noise_type == 0:\n",
    "        row,col,ch= image.shape\n",
    "        mean = 0\n",
    "        var = 0.1\n",
    "        sigma = var**0.5\n",
    "        gauss = np.random.normal(mean,sigma,(row,col,ch))\n",
    "        gauss = gauss.reshape(row,col,ch)\n",
    "        noisy = image + gauss\n",
    "        return noisy\n",
    "    elif noise_type == 1:\n",
    "        row,col,ch = image.shape\n",
    "        s_vs_p = 0.5\n",
    "        amount = 0.004\n",
    "        out = np.copy(image)\n",
    "        # Salt mode\n",
    "        num_salt = np.ceil(amount * image.size * s_vs_p)\n",
    "        coords = [np.random.randint(0, i - 1, int(num_salt))\n",
    "              for i in image.shape]\n",
    "        out[coords] = 1\n",
    "\n",
    "        # Pepper mode\n",
    "        num_pepper = np.ceil(amount* image.size * (1. - s_vs_p))\n",
    "        coords = [np.random.randint(0, i - 1, int(num_pepper))\n",
    "              for i in image.shape]\n",
    "        out[coords] = 0\n",
    "        return out\n",
    "    #elif noise_type == 2:\n",
    "    #    vals = len(np.unique(image))\n",
    "    #    vals = 2 ** np.ceil(np.log2(vals))\n",
    "    #    print(image)\n",
    "    #    noisy = np.random.poisson(image * vals) / float(vals)\n",
    "    #    return noisy\n",
    "    elif noise_type == 2:\n",
    "        row,col,ch = image.shape\n",
    "        gauss = np.random.randn(row,col,ch)\n",
    "        gauss = gauss.reshape(row,col,ch)        \n",
    "        noisy = image + (image * gauss)*0.05\n",
    "        return noisy\n",
    "    else:\n",
    "        return image\n",
    "    \n",
    "\"\"\"def make_small_image1(img):\n",
    "    img = cv2.resize(img, (random.randrange(45,46), random.randrange(13,14)))\n",
    "    return img\"\"\"\n",
    "\n",
    "def make_small_image1_2_5(img):\n",
    "    img = cv2.resize(img, (random.randrange(50,101), random.randrange(16,33)))\n",
    "    return img\n",
    "\n",
    "def make_small_image3_6(img):\n",
    "    img = cv2.resize(img, (random.randrange(75,101), random.randrange(28,33)))\n",
    "    return img\n",
    "\n",
    "def make_small_image4(img):\n",
    "    img = cv2.resize(img, (random.randrange(70,101), random.randrange(25,33)))\n",
    "    return img\n",
    "\n",
    "def make_large_image(img):\n",
    "    img = cv2.resize(img, (random.randrange(101,301), random.randrange(25,33)))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "741f0dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation_type7 = tf.keras.Sequential([#layers.experimental.preprocessing.RandomZoom((0,1),(0,1), fill_mode='nearest'),\n",
    "    layers.experimental.preprocessing.RandomRotation(0.01, fill_mode='nearest'),\n",
    "    layers.experimental.preprocessing.RandomTranslation((-0.005,0.005), (-0.05,0.05), fill_mode='nearest'),\n",
    "    #layers.experimental.preprocessing.Resizing(random.randrange(80,600), random.randrange(80,700), interpolation='bilinear'),\n",
    "    layers.experimental.preprocessing.Resizing(32, 100, interpolation='bilinear')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "5f4163cb",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [03:34, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-110-524b98a7062a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mimage_files_raw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_to_save_raw\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_files_raw_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_files_to_save_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mimage_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_file_to_save\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_files_raw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_to_save_raw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[0mimage_to_process\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage_making_before_augmentation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[0mimage_to_process\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchange_color_from_loaded_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_to_process\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mimage_to_process\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_to_process\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-7e3ea832b105>\u001b[0m in \u001b[0;36mimage_making_before_augmentation\u001b[1;34m(img_path)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mimage_making_before_augmentation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mimg_raw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;31m#(height, width, channel) = img_raw.shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m#image_maden = np.full((height*5, width*3, channel), 255, dtype=np.uint8)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m#image_maden[height*2:height*3, width*1:width*2, :] = img_raw\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#수정후. 이미지 사이즈만 정규 사이즈로(100,32)\n",
    "for (image_files_raw, image_to_save_raw) in tqdm(zip(image_files_raw_list, image_files_to_save_list)):\n",
    "    for (image_file, image_file_to_save) in (zip(image_files_raw, image_to_save_raw)):\n",
    "        image_to_process = image_making_before_augmentation(image_file)\n",
    "        image_to_process = change_color_from_loaded_data(image_to_process)\n",
    "        image_to_process = tf.expand_dims(image_to_process, 0)\n",
    "        augmented_image = data_augmentation_type7(image_to_process)\n",
    "        augmented_image = augmented_image[0].numpy().astype(\"uint8\")\n",
    "        #augmented_image = image_augmentation(augmented_image)\n",
    "        #augmented_image = add_noise(random.randrange(0, 5), augmented_image)\n",
    "        cv2.imwrite(image_file_to_save, augmented_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "8dcbe212",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]<ipython-input-137-51804ab2ba25>:60: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  out[coords] = 1\n",
      "<ipython-input-137-51804ab2ba25>:66: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  out[coords] = 0\n",
      "6it [08:46, 87.76s/it]\n"
     ]
    }
   ],
   "source": [
    "#작아진 이미지 사이즈를 더욱 작게 + 노이즈\n",
    "for (image_files_raw, image_to_save_raw) in tqdm(zip(image_files_to_save_list, image_files_to_small_list)):\n",
    "    for (image_file, image_file_to_save) in (zip(image_files_raw, image_to_save_raw)):\n",
    "        image_to_process = image_making_before_augmentation(image_file)\n",
    "        if image_to_save_raw == image_files444:\n",
    "            augmented_image = make_small_image4(image_to_process)\n",
    "        if image_to_save_raw == image_files333 or image_to_save_raw == image_files666:\n",
    "            augmented_image = make_small_image3_6(image_to_process)\n",
    "        else:\n",
    "            augmented_image = make_small_image1_2_5(image_to_process)\n",
    "        #augmented_image = image_augmentation(augmented_image)\n",
    "        augmented_image = add_noise(random.randrange(0, 4), augmented_image)\n",
    "        cv2.imwrite(image_file_to_save, augmented_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35081ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa601e08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da69db11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b326e69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c749ce1f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]<ipython-input-6-d9c39fdd40a5>:60: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  out[coords] = 1\n",
      "<ipython-input-6-d9c39fdd40a5>:66: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  out[coords] = 0\n",
      "6it [3:37:40, 2176.75s/it]\n"
     ]
    }
   ],
   "source": [
    "#수정전\n",
    "\n",
    "\n",
    "for (image_files_raw, image_to_save_raw) in tqdm(zip(image_files_raw_list, image_files_to_save_list)):\n",
    "    for (image_file, image_file_to_save) in (zip(image_files_raw, image_to_save_raw)):\n",
    "        image_to_process = image_making_before_augmentation(image_file)\n",
    "        image_to_process = change_color_from_loaded_data(image_to_process)\n",
    "        image_to_process = tf.expand_dims(image_to_process, 0)\n",
    "        augmented_image = data_augmentation_type7(image_to_process)\n",
    "        augmented_image = augmented_image[0].numpy().astype(\"uint8\")\n",
    "        augmented_image = image_augmentation(augmented_image)\n",
    "        augmented_image = add_noise(random.randrange(0, 5), augmented_image)\n",
    "        cv2.imwrite(image_file_to_save, augmented_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "ba6676df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_small_image1(img):\n",
    "    img = cv2.resize(img, (random.randrange(50,51), random.randrange(16,17)))\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518e8aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files_small = glob('img/train/img_small/type5/*.jpg')\n",
    "image_files_big = glob('img/train/img/type5/*.jpg')\n",
    "\n",
    "# 테스트용\n",
    "for (image_file, image_file_to_save) in tqdm(zip(image_files_big, image_files_small)):\n",
    "    image_to_process = image_making_before_augmentation(image_file)\n",
    "    image_to_process = make_small_image1(image_to_process)\n",
    "    augmented_image = image_augmentation(augmented_image)\n",
    "    augmented_image = add_noise(random.randrange(0, 4), augmented_image)\n",
    "    cv2.imwrite(image_file_to_save, image_to_process)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
