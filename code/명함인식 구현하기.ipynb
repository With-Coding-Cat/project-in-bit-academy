{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "honey-lindsay",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "heard-thread",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('name.jpg')\n",
    "orig = image.copy()   # 원본 이미지 복사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "northern-surname",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 1: Edged Detection\n"
     ]
    }
   ],
   "source": [
    "# Edge Detection\n",
    "\n",
    "r = 800.0 / image.shape[0]\n",
    "dim = (int(image.shape[1] * r), 800) \n",
    "image = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)  # 이미지를 resize\n",
    "\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)  # 이미지의 색공간을 BGR에서 Gray로 바꿈\n",
    "gray = cv2.GaussianBlur(gray, (3, 3), 0)   #GaussianBlur를 통해 blur 효과를 줌, 외관 검출을 더 쉽게 함\n",
    "edged = cv2.Canny(gray, 75, 200)  # Canny Edge Detection을 통해서 edge를 검출하게 됨\n",
    "\n",
    "print(\"STEP 1: Edged Detection\")  # 엣지가 검출된 이미지를 출력\n",
    "\n",
    "cv2.namedWindow('Image', cv2.WINDOW_NORMAL)  # 윈도우 사이즈 지정\n",
    "cv2.namedWindow('Edged', cv2.WINDOW_NORMAL)  # 윈도우 사이즈 지정\n",
    "cv2.imshow('Image', image)\n",
    "cv2.imshow('Edged', edged)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "opened-orlando",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 2: Find Contours of Paper\n"
     ]
    }
   ],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "(cnts, _) = cv.findContours(edged.copy(), cv.RETR_LIST, cv.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "cnts = sorted(cnts, key = cv.contourArea, reverse = True)\n",
    "\n",
    "screenCnt = None\n",
    "    \n",
    "for c in cnts:\n",
    "    peri = cv.arcLength(c, True)\n",
    "    approx = cv.approxPolyDP(c, 0.1 * peri, True)\n",
    "    \n",
    "    if len(approx) == 4:\n",
    "        screenCnt = approx\n",
    "        break\n",
    "            \n",
    "print(\"STEP 2: Find Contours of Paper\")\n",
    "cv.drawContours(image, [screenCnt], -1, (0, 255, 0), 2)\n",
    "cv.imshow(\"Outline\", image)    \n",
    "        \n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "speaking-correspondence",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "\n",
    "(cnts, _) = cv.findContours(edged.copy(), cv.RETR_LIST, cv.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "cnts = sorted(cnts, key = cv.contourArea, reverse = True)[:5]\n",
    "    \n",
    "    \n",
    "for c in cnts:\n",
    "    peri = cv.arcLength(c, True)\n",
    "    approx = cv.approxPolyDP(c, 0.02 * peri, True)\n",
    "\n",
    "    if len(approx) == 4:\n",
    "        screenCnt = approx\n",
    "        break\n",
    "\n",
    "    if screenCnt is None:\n",
    "        detected = 0\n",
    "        print (\"No plate detected\")\n",
    "    else:\n",
    "        detected = 1\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "collaborative-playback",
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_points(pts):\n",
    "    rect = np.zeros((4, 2), dtype = \"float32\")\n",
    "    \n",
    "    s = pts.sum(axis = 1)\n",
    "    rect[0] = pts[np.argmin(s)]\n",
    "    rect[2] = pts[np.argmax(s)]\n",
    "    \n",
    "    diff = np.diff(pts, axis = 1)\n",
    "    rect[1] = pts[np.argmin(diff)]\n",
    "    rect[3] = pts[np.argmax(diff)]\n",
    "    \n",
    "    return rect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "athletic-lawyer",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-51-26d42125884c>:17: DeprecationWarning: an integer is required (got type numpy.float32).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  warped = cv.warpPerspective(orig, M, (maxWidth, maxHeight))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 3: Apply perspective transform\n"
     ]
    }
   ],
   "source": [
    "rect = order_points(screenCnt.reshape(4, 2) / r)\n",
    "    \n",
    "(topLeft, topRight, bottomRight, bottomLeft) = rect\n",
    "    \n",
    "w1 = abs(bottomRight[0] - bottomLeft[0])\n",
    "w2 = abs(topRight[0] - topLeft[0])\n",
    "h1 = abs(topRight[0] - bottomRight[1])\n",
    "h2 = abs(topLeft[1] - bottomLeft[1])\n",
    "    \n",
    "maxWidth = max([w1, w2])\n",
    "maxHeight = max([h1, h2])\n",
    "    \n",
    "dst = np.float32([[0, 0], [maxWidth-1, 0], [maxWidth-1, maxHeight-1], [0, maxHeight-1]])\n",
    "    \n",
    "M = cv.getPerspectiveTransform(rect, dst)\n",
    "    \n",
    "warped = cv.warpPerspective(orig, M, (maxWidth, maxHeight))\n",
    "    \n",
    "print(\"STEP 3: Apply perspective transform\")\n",
    "cv.imshow(\"Warped\", warped)\n",
    "    \n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "specified-adjustment",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.1) c:\\users\\appveyor\\appdata\\local\\temp\\1\\pip-req-build-kh7iq4w7\\opencv\\modules\\imgproc\\src\\color.simd_helpers.hpp:92: error: (-2:Unspecified error) in function '__cdecl cv::impl::`anonymous-namespace'::CvtHelper<struct cv::impl::`anonymous namespace'::Set<3,4,-1>,struct cv::impl::A0x206ccf44::Set<1,-1,-1>,struct cv::impl::A0x206ccf44::Set<0,2,5>,2>::CvtHelper(const class cv::_InputArray &,const class cv::_OutputArray &,int)'\n> Invalid number of channels in input image:\n>     'VScn::contains(scn)'\n> where\n>     'scn' is 1\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-44-b6fa5c607dc2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mwarped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwarped\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mwarped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madaptiveThreshold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwarped\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mADAPTIVE_THRESH_MEAN_C\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTHRESH_BINARY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m21\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"STEP 4: Apply Adaptive Threshold\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.1) c:\\users\\appveyor\\appdata\\local\\temp\\1\\pip-req-build-kh7iq4w7\\opencv\\modules\\imgproc\\src\\color.simd_helpers.hpp:92: error: (-2:Unspecified error) in function '__cdecl cv::impl::`anonymous-namespace'::CvtHelper<struct cv::impl::`anonymous namespace'::Set<3,4,-1>,struct cv::impl::A0x206ccf44::Set<1,-1,-1>,struct cv::impl::A0x206ccf44::Set<0,2,5>,2>::CvtHelper(const class cv::_InputArray &,const class cv::_OutputArray &,int)'\n> Invalid number of channels in input image:\n>     'VScn::contains(scn)'\n> where\n>     'scn' is 1\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handmade-findings",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaged-three",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-silly",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "realistic-bathroom",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-43-a041cb797c8d>, line 72)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-43-a041cb797c8d>\"\u001b[1;36m, line \u001b[1;32m72\u001b[0m\n\u001b[1;33m    dst = np.float32([[0, 0], [maxWidhth-1, 0], [maxWidth-1], [maxHeight-1], [0. maxHeight-1]])\u001b[0m\n\u001b[1;37m                                                                                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# import numpy as np\n",
    "# import cv2 as cv\n",
    "\n",
    "# def order_points(pts):\n",
    "#     rect = np.zeros((4, 2), dtype = \"float32\")\n",
    "    \n",
    "#     s = pts.sum(axis = 1)\n",
    "#     rect[0] = pts[np.argmin(s)]\n",
    "#     rect[2] = pts[np.argmax(s)]\n",
    "    \n",
    "#     diff = np.diff(pts, axis = 1)\n",
    "#     rect[1] = pts[np.argmin(diff)]\n",
    "#     rect[3] = pts[np.argmax(diff)]\n",
    "    \n",
    "#     return rect\n",
    "\n",
    "# def auto_scan_image():\n",
    "#     image = cv.imread(\"opencv_test.jpg\")\n",
    "#     orig = image.copy()   # 원본 이미지 복사\n",
    "    \n",
    "#     r = 800.0 / image.shape[0]\n",
    "#     dim = (int(image.shape[1] * r), 800) \n",
    "#     image = cv.resize(image, dim, interpolation = cv.INTER_AREA)  # 이미지를 resize\n",
    "\n",
    "#     gray = cv.cvtColor(image, cv2.COLOR_BGR2GRAY)  # 이미지의 색공간을 BGR에서 Gray로 바꿈\n",
    "#     gray = cv.GaussianBlur(gray, (3, 3), 0)   #GaussianBlur를 통해 blur 효과를 줌, 외관 검출을 더 쉽게 함\n",
    "#     edged = cv.Canny(gray, 75, 200)  # Canny Edge Detection을 통해서 edge를 검출하게 됨\n",
    "\n",
    "#     print(\"STEP 1: Edged Detection\")  # 엣지가 검출된 이미지를 출력\n",
    "\n",
    "#     cv.namedWindow('Image', cv2.WINDOW_NORMAL)  # 윈도우 사이즈 지정\n",
    "#     cv.namedWindow('Edged', cv2.WINDOW_NORMAL)  # 윈도우 사이즈 지정\n",
    "#     cv.imshow('Image', image)\n",
    "#     cv.imshow('Edged', edged)\n",
    "\n",
    "#     cv.waitKey(0)\n",
    "#     cv.destroyAllWindows()\n",
    "    \n",
    "#     (_, cnts, _) = cv.findContours(edged.copy(), cv.RETR_LIST, cv.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "#     cnts = sorted(cnts, key = cv.contourArea, reverse = True)[:5]\n",
    "    \n",
    "    \n",
    "#     for c in cnts:\n",
    "#         peri = cv.arcLength(c, True)\n",
    "#         approx = cv.approxPolyDP(c, 0.02 * peri, True)\n",
    "        \n",
    "#         if len(approx) == 4:\n",
    "#             screenCnt = approx\n",
    "#             break\n",
    "            \n",
    "#     print(\"STEP 2: Find Contours of Paper\")\n",
    "#     cv.drawContours(image, [screenCnt], -1, (0, 255, 0), 2)\n",
    "#     cv.imshow('Outline', image)\n",
    "    \n",
    "#     cv.waitKey(0)\n",
    "#     cv.destroyAllWIndows()\n",
    "#     cv.waitKey(1)\n",
    "    \n",
    "#     rect = order_points(screenCnt, reshape(4, 2) / r)\n",
    "    \n",
    "#     (topLeft, topRight, bottomRight, bottomLeft) = rect\n",
    "    \n",
    "#     w1 = abs(bottomRight[0] - bottomLeft[0])\n",
    "#     w2 = abs(topRight[0] - topLeft[0])\n",
    "#     h1 = abs(topRight[0] - bottomRight[1])\n",
    "#     h2 = abs(topLeft[1] - bottomLeft[1])\n",
    "    \n",
    "#     maxWidth = max([w1, w2])\n",
    "#     maxHeight = max([h1, h2])\n",
    "    \n",
    "#     dst = np.float32([[0, 0], [maxWidhth-1, 0], [maxWidth-1], [maxHeight-1], [0. maxHeight-1]])\n",
    "    \n",
    "#     M = cv.getPerspectiveTransform(rect, dst)\n",
    "    \n",
    "#     warped = cv.warpPerspective(org, M, (maxWidth, maxHeight))\n",
    "    \n",
    "#     print(\"STEP 3: Apply perspective transform\")\n",
    "#     cv.imshow(\"Warped\", warped)\n",
    "    \n",
    "#     cv.waitKey(0)\n",
    "#     cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "celtic-reynolds",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
